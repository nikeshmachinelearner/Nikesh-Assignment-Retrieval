Coventry University Vertical Search (IR Coursework)
ğŸ“Œ Overview

This project implements a vertical search engine for Coventry Universityâ€™s PurePortal research outputs.
It covers the full pipeline of data collection, indexing, and retrieval:

Crawler (crawler.py)

Uses Selenium + BeautifulSoup to scrape researcher profile pages and extract publications (title, year, authors, links, type).

Saves data in JSONL (for indexing) and CSV (for inspection).

Each record has a stable ID (md5(title+url)) and crawl timestamp.

Indexer (indexer.py)

Reads the JSONL dataset and builds a Whoosh inverted index.

Schema fields include: title, authors, year, url, author_links, publication_type, crawled_at.

Supports incremental indexing (update_document).

Stores index files in models/index/.

Flask Search API + UI (app.py)

Provides a scholar-style search page.

REST API endpoints:

/api/search?q=term&sort=relevance|year|recent

/api/stats (index health + doc count)

Uses BM25F ranking with field boosts (title > authors > publication_type).

Search supports flexible matching across multiple fields.

Scheduler (optional) (scheduler.py)

Uses APScheduler to run crawler + indexer weekly (cron job).

Ensures the index stays up-to-date with new publications.

âš™ï¸ Requirements

Python 3.9+

Virtual environment recommended

Install dependencies:

pip install -r requirements.txt


Main packages used:

selenium, webdriver-manager, beautifulsoup4

whoosh, pyyaml, flask, pandas

ğŸš€ Usage
1. Crawl Data
python crawler.py


This generates:

data/publications.jsonl â€“ append-only dataset

data/publications.csv â€“ human-readable version

2. Build Index
python indexer.py


This creates/updates the Whoosh index in models/index/.

3. Run Search UI
python app.py


Open http://localhost:5000
 in your browser.
You can search by title, author, or type, sort by relevance/year/recent.

4. Automate Weekly (optional)
python scheduler.py


Runs crawler + indexer every Sunday 03:30 UTC.

ğŸ“‚ Project Structure
task/
â”‚
â”œâ”€â”€ crawler.py        # Scrapes PurePortal persons + publications
â”œâ”€â”€ indexer.py        # Builds Whoosh index from JSONL data
â”œâ”€â”€ app.py            # Flask API + search interface
â”œâ”€â”€ scheduler.py      # APScheduler job for weekly updates
â”‚
â”œâ”€â”€ data/             # Raw + processed crawl data (jsonl, csv)
â”œâ”€â”€ models/index/     # Whoosh index files
â”œâ”€â”€ templates/        # index.html for UI
â”œâ”€â”€ static/           # CSS + JS assets
â”‚
â”œâ”€â”€ config.yaml       # Paths + crawler settings
â”œâ”€â”€ requirements.txt  # Dependencies
â””â”€â”€ README.md         # Documentation

ğŸ” Example Query

Search: compensation
Results: Titles like "New perspectives on the governance of executive compensation" will appear, ranked by BM25F.

ğŸ“ Notes

Crawler is polite (accepts cookies, waits between requests, handles pagination).

JSONL is append-only, preserving crawl history.

Indexer is idempotent â€” re-running updates changed records instead of duplicating.

Flask app is debug-ready, but production deployment should use a WSGI server (e.g., Gunicorn).

ğŸ‘¨â€ğŸ“ Author

Name: Nikesh Adhikari

Course: Information Retrieval (MSc, Coventry University)

Task: Coursework â€“ Vertical Search System
